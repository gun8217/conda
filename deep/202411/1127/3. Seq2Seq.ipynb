{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN0joSzUYhN/sPJAAtB1my/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtHxf0hNUxYc","executionInfo":{"status":"ok","timestamp":1732690229366,"user_tz":-540,"elapsed":9703,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"3a6e3956-c135-47cd-d005-9e909326567d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.1 konlpy-0.6.0\n"]}]},{"cell_type":"markdown","source":["## 데이터셋 불러오기"],"metadata":{"id":"25q3Jii6U16W"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","import re\n","from konlpy.tag import Okt\n","from collections import defaultdict\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data.dataset import Dataset\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","df = pd.read_csv('https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"82WP1tcZUxR5","executionInfo":{"status":"ok","timestamp":1732690239488,"user_tz":-540,"elapsed":10124,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"56ae15f3-19b3-49d4-e899-9ff6f8e8f099"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Q            A  label\n","0           12시 땡!   하루가 또 가네요.      0\n","1      1지망 학교 떨어졌어    위로해 드립니다.      0\n","2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n","3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n","4          PPL 심하네   눈살이 찌푸려지죠.      0"],"text/html":["\n","  <div id=\"df-946f0bbd-b858-4396-bd83-d353085fc707\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-946f0bbd-b858-4396-bd83-d353085fc707')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-946f0bbd-b858-4396-bd83-d353085fc707 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-946f0bbd-b858-4396-bd83-d353085fc707');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f9b8c301-e2e0-4a4b-90ad-668fddc491b6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9b8c301-e2e0-4a4b-90ad-668fddc491b6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f9b8c301-e2e0-4a4b-90ad-668fddc491b6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## 데이터 전처리"],"metadata":{"id":"Aefk2OfzU5Jj"}},{"cell_type":"code","source":["okt = Okt()\n","\n","# Define special tokens\n","PAD_TOKEN = \"<PAD>\" # Padding Token\n","SOS_TOKEN = \"<SOS>\" # Start of Sequence Token\n","EOS_TOKEN = \"<EOS>\" # End of Sequence Token\n","\n","def preprocessing_text(text):\n","    # 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거\n","    result_text = re.sub('[^ ?,.!A-Za-z0-9가-힣+]', ' ', text)\n","    result_text = okt.morphs(result_text)\n","    return [SOS_TOKEN] + result_text + [EOS_TOKEN]"],"metadata":{"id":"q-WTaUQ_U47A","executionInfo":{"status":"ok","timestamp":1732690241619,"user_tz":-540,"elapsed":2135,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["questions = [preprocessing_text(text) for text in df['Q'].values]\n","answers = [preprocessing_text(text) for text in df['A'].values]"],"metadata":{"id":"JiU9VhUMU7A-","executionInfo":{"status":"ok","timestamp":1732690296860,"user_tz":-540,"elapsed":55244,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 단어사전(말뭉치) 설정"],"metadata":{"id":"IQLA9RIyU8R1"}},{"cell_type":"code","source":["\n","\n","# 어휘사전 생성을 위한 defaultdict 사용\n","vocab = defaultdict(lambda: len(vocab))\n","vocab[PAD_TOKEN] = 0  # PAD 토큰에 0 인덱스 할당\n","vocab[SOS_TOKEN] = 1  # SOS 토큰에 1 인덱스 할당\n","vocab[EOS_TOKEN] = 2  # EOS 토큰에 2 인덱스 할당\n","\n","# 어휘사전에 토큰 추가\n","for sentence in questions + answers:\n","    for token in sentence:\n","        vocab[token]  # 새로운 토큰에 대해 인덱스 자동 할당\n","\n","# 문자열에서 인덱스로의 변환 사전\n","str2idx = dict(vocab)  # 기본 사전 형태로 변환하여 사용\n","\n","# 인덱스에서 문자열로의 변환 사전 생성\n","idx2str = {idx: token for token, idx in vocab.items()}"],"metadata":{"id":"hxlWqq_CU-hC","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":8,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 데이터셋 설정"],"metadata":{"id":"dR4yYxmhVFXc"}},{"cell_type":"code","source":["from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","class ChatBotDataset(Dataset):\n","    def __init__(self):\n","        self.questions = questions\n","        self.answers = answers\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question_text = self.questions[idx]\n","        answers_text = self.answers[idx]\n","        question_idx = self.text2idx(question_text)\n","        answers_idx = self.text2idx(answers_text)\n","        return torch.tensor(question_idx), torch.tensor(answers_idx)\n","\n","    def text2idx(self, x):\n","        return [vocab[token] for token in x]\n","\n","dataset = ChatBotDataset()"],"metadata":{"id":"dPjiyZ7QVGyC","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":8,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","total_size = len(dataset)\n","train_size = int(0.8 * total_size)\n","test_size = total_size - train_size\n","\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"],"metadata":{"id":"kl_uT4ufVJ79","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":7,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    # 텍스트 데이터와 레이블 데이터를 분리\n","    question_data = [item[0] for item in batch]\n","    answers_data = [item[1] for item in batch]\n","\n","    # 텍스트 데이터만 패딩 처리\n","    padded_question_data = pad_sequence(question_data, batch_first=True, padding_value=vocab[PAD_TOKEN])\n","    padded_answers_data = pad_sequence(answers_data, batch_first=True, padding_value=vocab[PAD_TOKEN])\n","\n","    return padded_question_data, padded_answers_data\n","\n","\n","# collate_fn : 데이터를 넘겨주기 전에 사용할 함수\n","# batch_first = True -> 배치를 첫번째 차원으로 (batch_size, sequence_length, features)\n","train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)"],"metadata":{"id":"5f0HeKLlVLb7","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":7,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## 인코더"],"metadata":{"id":"lbqDUhnNVM2g"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n","        super(Encoder, self).__init__()\n","\n","        # 단어 사전의 개수 지정\n","        self.num_vocabs = num_vocabs\n","        # 임베딩 레이어 정의 (number of vocabs, embedding dimension)\n","        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n","        # GRU (embedding dimension)\n","        self.gru = nn.GRU(embedding_dim,\n","                          hidden_size,\n","                          num_layers=num_layers,\n","                          bidirectional=False)\n","\n","    def forward(self, x):\n","        x = self.embedding(x).permute(1, 0, 2)\n","        output, hidden = self.gru(x)\n","        return output, hidden"],"metadata":{"id":"hQJ3ca0RVOBu","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":6,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### 인코더 단계별로 실행"],"metadata":{"id":"Axo5AgfYVPe5"}},{"cell_type":"code","source":["NUM_VOCABS = len(vocab)\n","# Encoder 정의\n","encoder = Encoder(NUM_VOCABS,\n","                  hidden_size=32,\n","                  embedding_dim=64,\n","                  num_layers=1)"],"metadata":{"id":"NxMSbGaAVRku","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":6,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 64 # 임베딩 차원\n","x, y = next(iter(train_loader))\n","embedding = nn.Embedding(NUM_VOCABS, embedding_dim)\n","\n","# x :(batch_size, sequence_length)\n","# embedding(x) :(batch_size, sequence_length, embedding_dim)\n","# embedding(x).permute(1, 0, 2) : (sequence_length, batch_size, embedding_dim)\n","embedded = embedding(x).permute(1, 0, 2)\n","\n","print(x.shape)\n","print(embedded.shape)\n","# input:  (batch_size, sequence_length)\n","# output: (batch_size, sequence_length, embedding_dim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5KjXj5VVSql","executionInfo":{"status":"ok","timestamp":1732690296861,"user_tz":-540,"elapsed":6,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"cab8e33d-2cf8-4018-9484-df8f0acfc3da"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 15])\n","torch.Size([15, 16, 64])\n"]}]},{"cell_type":"code","source":["hidden_size = 32\n","embedding_dim = 64 # 임베딩 차원\n","gru = nn.GRU(embedding_dim,\n","             hidden_size,\n","             num_layers=1,\n","             bidirectional=False,\n","             batch_first=False, # batch_first=False로 지정\n","            )\n","# input       : (sequence_length, batch_size, embedding_dim)\n","# h0          : (Bidirectional(1) x number of layers(1), batch_size, hidden_size)\n","o, h = gru(embedded, None)\n","\n","print(o.shape)\n","print(h.shape)\n","# output      : (sequence_length, batch_size, hidden_size x bidirectional(1))\n","# hidden_state: (bidirectional(1) x number of layers(1), batch_size, hidden_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJswHqpMVVDy","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":958,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"073e3273-a1c2-41b4-9749-b0ec6eef89b6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([15, 16, 32])\n","torch.Size([1, 16, 32])\n"]}]},{"cell_type":"code","source":["# Encoder 정의\n","encoder = Encoder(NUM_VOCABS,\n","                  hidden_size=32,\n","                  embedding_dim=64,\n","                  num_layers=1)"],"metadata":{"id":"OwbV-pkcVWPM","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":26,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Encoder에 x 통과 후 output, hidden_size 의 shape 확인\n","# input(x)    : (batch_size, sequence_length)\n","o, h = encoder(x)\n","\n","print(o.shape)\n","print(h.shape)\n","# output      : (sequence_length, batch_size, hidden_size x bidirectional(1))\n","# hidden_state: (bidirectional(1) x number of layers(1), batch_size, hidden_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbhynpcFVXJN","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":26,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"8dc77f54-6434-4fea-cd77-20ba756fe77d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([15, 16, 32])\n","torch.Size([1, 16, 32])\n"]}]},{"cell_type":"markdown","source":["## 디코더"],"metadata":{"id":"VAbU_iEgVbdj"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers=1, dropout=0.2):\n","        super(Decoder, self).__init__()\n","        # 단어사전 개수\n","        self.num_vocabs = num_vocabs\n","        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(embedding_dim,\n","                          hidden_size,\n","                          num_layers=num_layers,\n","                          bidirectional=False,\n","                          batch_first = False)\n","\n","        # 최종 출력은 단어사전의 개수\n","        self.fc = nn.Linear(hidden_size, num_vocabs)\n","\n","    def forward(self, x, hidden_state):\n","        x = x.unsqueeze(0) # (1, batch_size) 로 변환 (1)\n","        embedded = F.relu(self.embedding(x))\n","        embedded = self.dropout(embedded)\n","        output, hidden = self.gru(embedded, hidden_state)\n","        output = self.fc(output.squeeze(0)) # (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n","        return output, hidden"],"metadata":{"id":"BiHur1lCVcbN","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":24,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### 디코더 단계적으로 실행"],"metadata":{"id":"eeqd1UqOVjUS"}},{"cell_type":"markdown","source":["Embedding Layer의 입/출력 shape에 대한 이해"],"metadata":{"id":"qse3MDhiVoUG"}},{"cell_type":"code","source":["x = torch.abs(torch.randn(size=(1, 32)).long())\n","print(x)\n","x.shape\n","# batch_size = 32 이라 가정했을 때,\n","# (1, batch_size)\n","# 여기서 batch_size => (1, batch_size) 로 shape 변환을 선행"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65aShvkyVlLw","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":24,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"729dc408-8936-4f27-fb1b-619ff4bb5280"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n","         0, 0, 0, 0, 0, 0, 0, 0]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["NUM_VOCABS = len(vocab)\n","embedding_dim= 64# 임베딩 차원\n","embedding= nn.Embedding(NUM_VOCABS , embedding_dim)\n","\n","embedded= embedding(x)\n","embedded.shape\n","# embedding 출력\n","# (1, batch_size, embedding_dim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNgq1BTpVpSU","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":22,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"2be9397d-5810-4e7e-9a99-290c244b956c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 64])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["GRU Layer의 입/출력 shape에 대한 이해"],"metadata":{"id":"6T4ffHYBVpyy"}},{"cell_type":"code","source":["hidden_size = 32\n","\n","gru = nn.GRU(embedding_dim,\n","             hidden_size,\n","             num_layers=1,\n","             bidirectional=False,\n","             batch_first=False, # batch_first=False로 지정\n","            )\n","\n","o, h = gru(embedded)\n","\n","print(o.shape)\n","# output shape: (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n","print(h.shape)\n","# hidden_state shape: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrGx-IthVqz-","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":21,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"1e32fbd1-546a-410d-e6f5-bd35a0e276d1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 32, 32])\n","torch.Size([1, 32, 32])\n"]}]},{"cell_type":"markdown","source":["최종 출력층(FC) shape에 대한 이해"],"metadata":{"id":"ZC-8PkZ7VtA7"}},{"cell_type":"code","source":["fc = nn.Linear(32, NUM_VOCABS) # 출력은 단어사전의 개수로 가정\n","\n","output = fc(o[0])\n","\n","print(o[0].shape)\n","print(output.shape)\n","# input : (batch_size, output from GRU)\n","# output: (batch_size, output dimension)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31aiFNOzVtiz","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":20,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"c6c338c4-1797-4d5f-858a-b46255415f50"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 32])\n","torch.Size([32, 12659])\n"]}]},{"cell_type":"markdown","source":["인코더 -> 디코더 입출력 shape"],"metadata":{"id":"aPIvWPY6Vvko"}},{"cell_type":"code","source":["decoder = Decoder(num_vocabs=NUM_VOCABS,\n","                  hidden_size=32,\n","                  embedding_dim=64,\n","                  num_layers=1)"],"metadata":{"id":"OL5Eqph8Vv9P","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":20,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["x, y = next(iter(train_loader))\n","\n","o, h = encoder(x)\n","\n","print(o.shape, h.shape)\n","# output      : (sequence_length, batch_size, hidden_size x bidirectional(1))\n","# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGBWxUUTVyUo","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":19,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"2c205c19-7c58-43d6-e9e1-681506f27c79"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([15, 16, 32]) torch.Size([1, 16, 32])\n"]}]},{"cell_type":"code","source":["x = torch.abs(torch.full(size=(16,), fill_value=vocab[SOS_TOKEN]).long())\n","print(x)\n","x.shape\n","# batch_size = 16 이라 가정(16개의 SOS 토큰)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqZjeyV9VzrW","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":19,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"adb7bfb8-a874-4144-960b-7c09315695f7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([16])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["decoder_output, decoder_hidden = decoder(x, h)\n","decoder_output.shape, decoder_hidden.shape\n","# (batch_size, num_vocabs), (1, batch_size, hidden_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dm9cE8FDV0j9","executionInfo":{"status":"ok","timestamp":1732690297815,"user_tz":-540,"elapsed":17,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"4d2b0583-311f-4200-b526-c7c3a296fd0f"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([16, 12659]), torch.Size([1, 16, 32]))"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## Seq2Seq"],"metadata":{"id":"c7qb5HlxV3nr"}},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, inputs, outputs, teacher_forcing_ratio=0.5):\n","        # inputs : (batch_size, sequence_length)\n","        # outputs: (batch_size, sequence_length)\n","\n","        batch_size, output_length = outputs.shape\n","        output_num_vocabs = self.decoder.num_vocabs\n","\n","        # 리턴할 예측된 outputs를 저장할 임시 변수\n","        # (sequence_length, batch_size, num_vocabs)\n","        predicted_outputs = torch.zeros(output_length, batch_size, output_num_vocabs).to(self.device)\n","\n","        # 인코더에 입력 데이터 주입, encoder_output은 버리고 hidden_state 만 살립니다.\n","        # 여기서 hidden_state가 디코더에 주입할 context vector 입니다.\n","        # (Bidirectional(1) x number of layers(1), batch_size, hidden_size)\n","        _, decoder_hidden = self.encoder(inputs)\n","\n","        # (batch_size) shape의 SOS TOKEN으로 채워진 디코더 입력 생성\n","        decoder_input = torch.full((batch_size,), vocab[SOS_TOKEN], device=self.device)\n","\n","        # 순회하면서 출력 단어를 생성합니다.\n","        # 0번째는 SOS TOKEN이 위치하므로, 1번째 인덱스부터 순회합니다.\n","        for t in range(0, output_length):\n","            # decoder_input : 디코더 입력 (batch_size) 형태의 SOS TOKEN로 채워진 입력\n","            # decoder_output: (batch_size, num_vocabs)\n","            # decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size), context vector와 동일 shape\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","\n","            # t번째 단어에 디코더의 output 저장\n","            predicted_outputs[t] = decoder_output\n","\n","            # teacher forcing 적용 여부 확률로 결정\n","            # teacher forcing 이란: 정답치를 다음 RNN Cell의 입력으로 넣어주는 경우. 수렴속도가 빠를 수 있으나, 불안정할 수 있음\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            # top1 단어 토큰 예측\n","            top1 = decoder_output.argmax(1)\n","\n","            # teacher forcing 인 경우 ground truth 값을, 그렇지 않은 경우, 예측 값을 다음 input으로 지정\n","            decoder_input = outputs[:, t] if teacher_force else top1\n","        return predicted_outputs.permute(1, 0, 2) # (batch_size, sequence_length, num_vocabs)로 변경"],"metadata":{"id":"soQePxPvV4-Z","executionInfo":{"status":"ok","timestamp":1732690297816,"user_tz":-540,"elapsed":17,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["### seq2seq 단계적 확인"],"metadata":{"id":"o52l0IehV7Pm"}},{"cell_type":"code","source":["# Encoder 정의\n","encoder = Encoder(num_vocabs=len(vocab),\n","                       hidden_size=32,\n","                       embedding_dim=64,\n","                       num_layers=1)\n","# Decoder 정의\n","decoder = Decoder(num_vocabs=len(vocab),\n","                       hidden_size=32,\n","                       embedding_dim=64,\n","                       num_layers=1)\n","# Seq2Seq 정의\n","seq2seq = Seq2Seq(encoder, decoder, 'cpu')"],"metadata":{"id":"hsE0xoG7V9Gr","executionInfo":{"status":"ok","timestamp":1732690774930,"user_tz":-540,"elapsed":332,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["x, y = next(iter(train_loader))\n","print(x.shape, y.shape)\n","# (batch_size, sequence_length), (batch_size, sequence_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhkDZX52V_CL","executionInfo":{"status":"ok","timestamp":1732690776913,"user_tz":-540,"elapsed":361,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"ea695005-318e-44b3-a5fc-36aab333620c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 15]) torch.Size([16, 17])\n"]}]},{"cell_type":"code","source":["output= seq2seq(x, y)\n","print(output.shape)\n","# (batch_size, sequence_length, num_vocabs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UADYgklPWAKP","executionInfo":{"status":"ok","timestamp":1732690779902,"user_tz":-540,"elapsed":328,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"3b909647-507c-4af5-d83c-13c1875431ec"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 17, 12659])\n"]}]},{"cell_type":"markdown","source":["## 인코더 디코더 정의"],"metadata":{"id":"NlwROCeTWN8P"}},{"cell_type":"code","source":["NUM_VOCABS = len(vocab)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","HIDDEN_SIZE = 512\n","EMBEDDIMG_DIM = 256\n","\n","print(f'num_vocabs: {NUM_VOCABS}\\n======================')\n","\n","# Encoder 정의\n","encoder = Encoder(num_vocabs=NUM_VOCABS,\n","                  hidden_size=HIDDEN_SIZE,\n","                  embedding_dim=EMBEDDIMG_DIM,\n","                  num_layers=1)\n","# Decoder 정의\n","decoder = Decoder(num_vocabs=NUM_VOCABS,\n","                  hidden_size=HIDDEN_SIZE,\n","                  embedding_dim=EMBEDDIMG_DIM,\n","                  num_layers=1)\n","\n","# Seq2Seq 생성\n","# encoder, decoder를 device 모두 지정\n","model = Seq2Seq(encoder.to(device), decoder.to(device), device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TD0KPu5rWST7","executionInfo":{"status":"ok","timestamp":1732690784805,"user_tz":-540,"elapsed":528,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"2cc25b90-8062-4039-9349-301cf49f2e22"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["num_vocabs: 12659\n","======================\n","Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(12659, 256)\n","    (gru): GRU(256, 512)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(12659, 256)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (gru): GRU(256, 512)\n","    (fc): Linear(in_features=512, out_features=12659, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["## 학습 함수"],"metadata":{"id":"cLauJI_YWTt0"}},{"cell_type":"code","source":["LR = 1e-3\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=vocab[PAD_TOKEN])\n","\n","def train(model, data_loader, optimizer, loss_fn, device):\n","    model.train()\n","    running_loss = 0\n","\n","    for x, y in data_loader:\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # output: (batch_size, sequence_length, num_vocabs)\n","        output = model(x, y)\n","        output_dim = output.size(2) # num_vocabs\n","\n","        # 1번 index 부터 슬라이싱한 이유는 0번 index가 SOS TOKEN 이기 때문\n","        # (batch_size*sequence_length, num_vocabs) 로 변경\n","        output = output.reshape(-1, output_dim)\n","\n","        # (batch_size,sequence_length) -> (batch_size*sequence_length) 로 변경\n","        y = y.view(-1)\n","\n","        # Loss 계산\n","        loss = loss_fn(output, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","\t\t\t\t# loss.item() : 배치의 평균 오차\n","\t\t\t\t#  x.size(0) : 배치 수\n","        running_loss += loss.item() * x.size(0) # 배치의 토탈 오차\n","        # 위와 같이 하는 이유는 배치 사이즈가 다를 수 있어서\n","    return running_loss / len(data_loader)"],"metadata":{"id":"wAFi1U69WVLH","executionInfo":{"status":"ok","timestamp":1732690791388,"user_tz":-540,"elapsed":6585,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## 평가함수"],"metadata":{"id":"HH6W3-_0WVrW"}},{"cell_type":"code","source":["def evaluate(model, data_loader, loss_fn, device):\n","    model.eval()\n","\n","    eval_loss = 0\n","\n","    with torch.no_grad():\n","        for x, y in data_loader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x, y)\n","            output_dim = output.size(2)\n","            output = output.reshape(-1, output_dim)\n","            y = y.view(-1)\n","\n","            # Loss 계산\n","            loss = loss_fn(output, y)\n","\n","            eval_loss += loss.item() * x.size(0)\n","\n","    return eval_loss / len(data_loader)"],"metadata":{"id":"kUIS4wPMWXYU","executionInfo":{"status":"ok","timestamp":1732690791388,"user_tz":-540,"elapsed":5,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["## 모델의 결과를 한글로 변환"],"metadata":{"id":"kxPCigR4WYcS"}},{"cell_type":"code","source":["def sequence_to_sentence(sequences, index2word):\n","    outputs = []\n","    for p in sequences:\n","\n","        word = index2word[p]\n","        if p not in [SOS_TOKEN, EOS_TOKEN, PAD_TOKEN]:\n","            outputs.append(word)\n","        if word == EOS_TOKEN:\n","            break\n","    return ' '.join(outputs)"],"metadata":{"id":"2_32CEprWbJR","executionInfo":{"status":"ok","timestamp":1732690791388,"user_tz":-540,"elapsed":4,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["## 랜덤으로 샘플링 해서 결과 확인"],"metadata":{"id":"NIqKjbwnWcg6"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, SubsetRandomSampler\n","def random_evaluation(model, dataset, index2word, device, n=10):\n","\n","    n_samples = len(dataset)\n","    indices = list(range(n_samples))\n","    np.random.shuffle(indices)      # Shuffle\n","    sampled_indices = indices[:n]   # Sampling N indices\n","\n","    # 샘플링한 데이터를 기반으로 DataLoader 생성\n","    sampler = SubsetRandomSampler(sampled_indices)\n","    sampled_dataloader = DataLoader(dataset, batch_size=10, sampler=sampler, collate_fn = collate_fn)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in sampled_dataloader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x, y, teacher_forcing_ratio=0)\n","            # output: (number of samples, sequence_length, num_vocabs)\n","\n","            preds = output.detach().cpu().numpy()\n","            x = x.detach().cpu().numpy()\n","            y = y.detach().cpu().numpy()\n","\n","            for i in range(n):\n","                print(f'질문   : {sequence_to_sentence(x[i], index2word)}')\n","                print(f'답변   : {sequence_to_sentence(y[i], index2word)}')\n","                print(f'예측답변: {sequence_to_sentence(preds[i].argmax(1), index2word)}')\n","                print('==='*10)"],"metadata":{"id":"hEeYIWcTWeu0","executionInfo":{"status":"ok","timestamp":1732690791388,"user_tz":-540,"elapsed":4,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["## 모델 학습 및 저장"],"metadata":{"id":"yF7qwG8dWiw4"}},{"cell_type":"code","source":["# NUM_EPOCHS = 10\n","# STATEDICT_PATH = 'seq2seq-chatbot-kor.pt'\n","\n","# best_loss = np.inf\n","\n","# for epoch in range(NUM_EPOCHS):\n","#     loss = train(model, train_loader, optimizer, loss_fn, device)\n","\n","#     val_loss = evaluate(model, test_loader, loss_fn, device)\n","\n","#     if val_loss < best_loss:\n","#         best_loss = val_loss\n","#         torch.save(model.state_dict(), STATEDICT_PATH)\n","\n","#     if epoch % 5 == 0:\n","#         print(f'epoch: {epoch+1}, loss: {loss:.4f}, val_loss: {val_loss:.4f}')\n","\n","\n","# torch.save(model, STATEDICT_PATH)"],"metadata":{"id":"k1OAgSMSWf9G","executionInfo":{"status":"ok","timestamp":1732690791388,"user_tz":-540,"elapsed":4,"user":{"displayName":"최진영","userId":"04611147725648038476"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["## 모델 불러오기"],"metadata":{"id":"wx50xL6pWvMs"}},{"cell_type":"code","source":["STATEDICT_PATH = 'seq2seq-chatbot-kor.pt'\n","model.load_state_dict(torch.load(STATEDICT_PATH))\n","random_evaluation(model, test_dataset, idx2str, device, n=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"Wy9L7zlEWwfW","executionInfo":{"status":"error","timestamp":1732690791388,"user_tz":-540,"elapsed":4,"user":{"displayName":"최진영","userId":"04611147725648038476"}},"outputId":"253054d2-1442-4b67-c0e8-e4077097feea"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-36-cf166fa8d7e2>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(STATEDICT_PATH))\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-cf166fa8d7e2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSTATEDICT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'seq2seq-chatbot-kor.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTATEDICT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrandom_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1361\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   1813\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0m_internal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \"\"\"\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."]}]}]}